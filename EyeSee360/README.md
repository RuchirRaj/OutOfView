# EyeSee360
Head-mounted displays allow user to augment reality or dive into a virtual one. However, these 3D spaces often come with problems
due to objects that may be out of view. Visualizing these out-of-view objects is useful under certain scenarios, such as situation
monitoring during ship docking. To address this, we designed a lo-fi prototype of our EyeSee360 system, and based on user feedback, subsequently implemented EyeSee360. We evaluate our technique against well-known 2D off-screen object visualization techniques (Arrow, Halo, Wedge) adapted for head-mounted Augmented Reality, and found that EyeSee360 results in lowest error for direction estimation of out-of-view objects. Based on our findings, we outline the limitations of our approach and discuss the usefulness of our developed lo-fi prototyping tool.

DOI: https://doi.org/10.1145/3131277.3132175
